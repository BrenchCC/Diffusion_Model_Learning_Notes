# Diffusion Model Learning Notes

这是一个扩散模型（Diffusion Model）的学习项目，实现了一个简化版的DDPM（Denoising Diffusion Probabilistic Models）用于图像去噪任务。该项目主要用于理解扩散模型的基本原理和实现细节。

## 项目结构

```
.
├── README.md                 # 项目说明文档
├── ddpm_train.py             # 训练脚本
├── ddpm_infer.py             # 推理脚本
├── images/                   # 图像目录
│   ├── demo.png              # 示例图像
│   └── inference_result.png  # 推理结果
├── model_ckpt/               # 模型 checkpoint 目录
│   └── demo_unet.pth         # 预训练模型
├── models/                   # 模型定义目录
│   ├── __init__.py
│   └── unet_model.py         # U-Net 模型实现
└── assay/                    # 参考文献目录
```

## 安装依赖

```bash
pip install -r requirements.txt
```

## 快速开始

### 训练模型

```bash
python ddpm_train.py --img_size 256 --train_steps 3000 --lr 1e-3
```

参数说明：
- `--img_size`: 图像大小，默认 256
- `--batch_size`: 批次大小，默认 1
- `--train_steps`: 训练步数，默认 3000
- `--lr`: 学习率，默认 1e-3
- `--image_path`: 训练图像路径，默认 images/demo.png
- `--model_save_path`: 模型保存路径，默认 model_ckpt/demo_unet.pth

### 推理预测

```bash
python ddpm_infer.py --img_size 256
```

参数说明：
- `--img_size`: 图像大小，默认 256
- `--image_path`: 参考图像路径，默认 images/demo.png
- `--model_path`: 模型路径，默认 model_ckpt/demo_unet.pth
- `--result_path`: 结果保存路径，默认 images/inference_result.png

## 模型架构

### U-Net 架构

本项目使用了一个简化版的 U-Net 架构，主要特点：
- 包含编码器（下采样）和解码器（上采样）部分
- 时间步嵌入（Time Embedding）注入到每个卷积块
- 使用残差连接和跳跃连接保留空间信息
- 支持不同的通道配置

### 扩散过程

扩散模型的核心是通过逐步加噪和去噪来学习数据分布：

1. **加噪过程**：将原始图像逐步添加高斯噪声，直到图像完全变成随机噪声
2. **去噪过程**：训练模型从含噪图像中恢复原始图像

## 代码逻辑说明

### 1. 代码逻辑拆解：这是一个"加权混合"
示例加噪函数本质上是一个**线性插值**：

### 2. 模型的实际输入与输出

在训练和推理时，U-Net 实际上是在处理以下数据：

#### **输入 (Input)**

模型接收两个东西：

1. **混合后的图片 (`x`)**:
* 形状: `(Batch_Size, 3, 64, 64)`
* 内容: 这是一张**既有原图特征，又有噪点**的模糊图片。
* 举例: 假设  (中等噪声)，模型看到的就像是一个隔着磨砂玻璃或者信号极差的电视画面。


2. **时间步 (`t`)**:
* 形状: `(Batch_Size,)`
* 内容: 一个整数（例如 500）。
* 作用: **这是给模型的"提示线索"**。它告诉模型："这张图里混入了大约 40% 的噪声，原本的信号只剩 60% 了，请按这个比例去猜原图。"



#### **输出 (Output)**

模型输出一个东西：

1. **预测的原图 (`x_pred`)**:
* 形状: `(Batch_Size, 3, 64, 64)`
* 内容: 模型认为"去掉噪声后"应该长样子的**干净图片**。



---

### 3. 去噪原理：模型在做什么？

为了理解原理，我们可以把上面的代码写成一个数学等式。

模型的目标是求出 **原图**。
理论上，如果我们知道 **随机噪声** 具体是多少，直接做减法就行了：

**但是** 关键问题在于：**推理时，我们不知道"随机噪声"具体长什么样（它是随机的）。**

所以，神经网络（U-Net）的作用就是利用它强大的**特征提取能力**和**记忆能力**来解决这个无解方程：

1. **利用先验知识（记忆）**：模型在训练中看了成千上万次这张图（Overfitting Demo中）。它已经记住了原图的线条、颜色分布和纹理。
2. **利用提示（时间步 t）**：模型通过  算出了 。它知道："现在这张图里，有 40% 是我不想要的随机像素，有 60% 是我要保留的结构。"
3. **模式识别**：
* 模型看这张图，发现有些像素杂乱无章（符合高斯噪声分布），它判定这是**噪声**。
* 有些像素连成了线条（符合它记忆中的图像轮廓），它判定这是**信号**。
* 它尝试构造一张图，这张图在乘以  后，非常接近输入图中"有规律"的那一部分。



### 4. 通俗举例（数值模拟）

假设我们只关注图片中的**一个像素点**。

* **原图数值 ()**: `100` (比如是天空的蓝色)
* **噪声数值 ()**: `10` (随机生成的)
* **时间步 ()**: 对应权重 

**加噪过程 (你的代码)**:


**模型的任务**:

* **输入给模型**: `55` (像素值) 和 `w = 0.5`。
* **模型内心独白**: "我看到了 `55`，权重是 `0.5`。公式是 。
这个随机数可能是 -100 到 100 之间的任何数。
* 如果原图是 0，随机数得是 110（不太可能）。
* 如果原图是 200，随机数得是 -90（也不太可能）。
* **根据我训练的记忆**，这个位置通常是天空，值大概在 `90-110` 之间。最合理的猜测是原图等于 `100`，这时候随机数是 `10`，这很符合正态分布。"


* **模型输出**: `100`。

这就是去噪：**结合输入的模糊信息 + 权重的提示 + 训练得来的先验分布（记忆），猜出最可能的原图。**

## 实验结果

推理结果将生成一个包含三张图像的可视化：
1. **Ground Truth**: 原始图像
2. **Noisy Input**: 带噪声的输入图像
3. **Inference Output**: 模型去噪后的输出

结果保存为 `images/inference_result.png`。

## 参考资料

- [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)
- [Improved Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2102.09672)
- [Diffusion Models Beat GANs on Image Synthesis](https://arxiv.org/abs/2105.05233)

## License

MIT License